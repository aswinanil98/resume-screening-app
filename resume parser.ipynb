{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb8dcdbb",
   "metadata": {},
   "source": [
    "# Importing Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eeae9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    " from sklearn.model_selection import GridSearchCV`a\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016f5b8b",
   "metadata": {},
   "source": [
    "# Reading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310bcdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"UpdatedResumeDataSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d1b4aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category                                             Resume\n",
       "0  Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
       "2  Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98fdeb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "Java Developer               84\n",
       "Testing                      70\n",
       "DevOps Engineer              55\n",
       "Python Developer             48\n",
       "Web Designing                45\n",
       "HR                           44\n",
       "Hadoop                       42\n",
       "Blockchain                   40\n",
       "ETL Developer                40\n",
       "Operations Manager           40\n",
       "Data Science                 40\n",
       "Sales                        40\n",
       "Mechanical Engineer          40\n",
       "Arts                         36\n",
       "Database                     33\n",
       "Electrical Engineering       30\n",
       "Health and fitness           30\n",
       "PMO                          30\n",
       "Business Analyst             28\n",
       "DotNet Developer             28\n",
       "Automation Testing           26\n",
       "Network Security Engineer    25\n",
       "SAP Developer                24\n",
       "Civil Engineer               24\n",
       "Advocate                     20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Category\"].value_counts() # we can see that the data is imbalanced this can effect the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2554d042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category    0\n",
       "Resume      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4bb13",
   "metadata": {},
   "source": [
    "# Resampling to Balance the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0fa62a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5bac19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "max_count=df[\"Category\"].value_counts().max()\n",
    "for category in df['Category'].unique():\n",
    "    categorical_data=df[df['Category']==category]\n",
    "    if len(categorical_data)<max_count:\n",
    "        balanced_df=resample(categorical_data,n_samples=max_count,replace=True,random_state=42)\n",
    "    else:\n",
    "        balanced_df=resample(categorical_data,n_samples=max_count,replace=False,random_state=42)\n",
    "    df_new.append(balanced_df)\n",
    "    \n",
    "df=pd.concat(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb65ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "Data Science                 84\n",
       "Electrical Engineering       84\n",
       "Blockchain                   84\n",
       "DotNet Developer             84\n",
       "ETL Developer                84\n",
       "Hadoop                       84\n",
       "Database                     84\n",
       "PMO                          84\n",
       "Network Security Engineer    84\n",
       "DevOps Engineer              84\n",
       "Python Developer             84\n",
       "Operations Manager           84\n",
       "Automation Testing           84\n",
       "HR                           84\n",
       "SAP Developer                84\n",
       "Business Analyst             84\n",
       "Java Developer               84\n",
       "Civil Engineer               84\n",
       "Health and fitness           84\n",
       "Sales                        84\n",
       "Mechanical Engineer          84\n",
       "Web Designing                84\n",
       "Arts                         84\n",
       "Advocate                     84\n",
       "Testing                      84\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c60ab2",
   "metadata": {},
   "source": [
    "# Cleaning The Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3090c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "358cde7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Resume\"]=df[\"Resume\"].apply(lambda x:cleaned_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c3f40c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>personal skills â ability to quickly grasp tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>personal skills â ability to quickly grasp tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>education details mca ymcaust faridabad haryan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>education details btech rayat and bahra instit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>skills programming languages python pandas num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>Testing</td>\n",
       "      <td>â good logical and analytical skills â positiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>Testing</td>\n",
       "      <td>skill set os windows xp database mysql sql ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>Testing</td>\n",
       "      <td>skill set os windows xp database mysql sql ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>Testing</td>\n",
       "      <td>personal skills â quick learner â eagerness to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Testing</td>\n",
       "      <td>personal skills â quick learner â eagerness to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category                                             Resume\n",
       "38   Data Science  personal skills â ability to quickly grasp tec...\n",
       "28   Data Science  personal skills â ability to quickly grasp tec...\n",
       "14   Data Science  education details mca ymcaust faridabad haryan...\n",
       "7    Data Science  education details btech rayat and bahra instit...\n",
       "20   Data Science  skills programming languages python pandas num...\n",
       "..            ...                                                ...\n",
       "899       Testing  â good logical and analytical skills â positiv...\n",
       "926       Testing  skill set os windows xp database mysql sql ser...\n",
       "926       Testing  skill set os windows xp database mysql sql ser...\n",
       "924       Testing  personal skills â quick learner â eagerness to...\n",
       "896       Testing  personal skills â quick learner â eagerness to...\n",
       "\n",
       "[2100 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2625697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='personal skills â\\x9e¢ ability to quickly grasp technical aspects and willingness to learn â\\x9e¢ high energy levels  result oriented. education details january 2018 master of engineering computer technology  application bhopal, madhya pradesh truba institute of engineering  information technologyjanuary 2010 b.e. computer science bhopal, madhya pradesh rkdf institute of science and technology college of engineeringjanuary 2006 polytechnic information technology vidisha, madhya pradesh sati engineering college in vidishajanuary 2003 m.tech thesis detail  bmch school in ganj basodadata science i have six month experience in data science. key skills - experience in machine learning, deep leaning, nlp, python, sql, web scraping good knowledge in computer subjects and ability to updateskill details experience in machine learning, deep learning, nlp, python, sql, web crawling, html,css.- exprience - less than 1 year monthscompany details company - rnt.ai technology solutiondescription - text classification using machine learning algorithms with python.practical knowledge of deep learning algorithms such as â\\xa0recurrent neural networks(rnn).develop custom data models and algorithms to apply to datasetexperience with python packages like pandas, scikit-learn, tensor flow, numpy, matplotliv, nltk.comfort with sql, â\\xa0mysqlsentiment analysis.â\\xa0apply leave dataset using classification technique like tf--idf , lsa with cosine similarity using machine learning algorithms.web crawling using selenium web driver and beautiful soup with python.company - life insurance corporation of india bhopaldescription - ã¼â\\xa0explaining policy features and the benefitsã¼ updated knowledge of life insurance products and shared with customers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41c3f044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'personal skills â ability to quickly grasp technical aspects and willingness to learn â high energy levels result oriented education details january master of engineering computer technology application bhopal madhya pradesh truba institute of engineering information technologyjanuary be computer science bhopal madhya pradesh rkdf institute of science and technology college of engineeringjanuary polytechnic information technology vidisha madhya pradesh sati engineering college in vidishajanuary mtech thesis detail bmch school in ganj basodadata science i have six month experience in data science key skills experience in machine learning deep leaning nlp python sql web scraping good knowledge in computer subjects and ability to updateskill details experience in machine learning deep learning nlp python sql web crawling htmlcss exprience less than year monthscompany details company rntai technology solutiondescription text classification using machine learning algorithms with pythonpractical knowledge of deep learning algorithms such as â recurrent neural networksrnndevelop custom data models and algorithms to apply to datasetexperience with python packages like pandas scikitlearn tensor flow numpy matplotliv nltkcomfort with sql â mysqlsentiment analysisâ apply leave dataset using classification technique like tfidf lsa with cosine similarity using machine learning algorithmsweb crawling using selenium web driver and beautiful soup with pythoncompany life insurance corporation of india bhopaldescription ã¼â explaining policy features and the benefitsã¼ updated knowledge of life insurance products and shared with customers'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text(text)# we can see the data is cleaned well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d432b3c2",
   "metadata": {},
   "source": [
    "# Vectorizing the text data using tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "347937d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df[\"Resume\"]\n",
    "y=df[\"Category\"]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b144d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=TfidfVectorizer()\n",
    "X_train=vect.fit_transform(X_train)\n",
    "X_test=vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ae18891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16863b4",
   "metadata": {},
   "source": [
    "# Training the Data with RF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1043ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()\n",
    "model=rf.fit(X_train,y_train)\n",
    "pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d913bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0196ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b27a235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                 Advocate       1.00      1.00      1.00        14\n",
      "                     Arts       1.00      1.00      1.00        15\n",
      "       Automation Testing       1.00      1.00      1.00        19\n",
      "               Blockchain       1.00      1.00      1.00        28\n",
      "         Business Analyst       1.00      1.00      1.00        12\n",
      "           Civil Engineer       1.00      1.00      1.00        22\n",
      "             Data Science       1.00      1.00      1.00        19\n",
      "                 Database       1.00      1.00      1.00        11\n",
      "          DevOps Engineer       1.00      1.00      1.00        18\n",
      "         DotNet Developer       1.00      1.00      1.00         8\n",
      "            ETL Developer       1.00      1.00      1.00        17\n",
      "   Electrical Engineering       1.00      1.00      1.00        21\n",
      "                       HR       1.00      1.00      1.00        18\n",
      "                   Hadoop       1.00      1.00      1.00        24\n",
      "       Health and fitness       1.00      1.00      1.00        19\n",
      "           Java Developer       1.00      1.00      1.00        15\n",
      "      Mechanical Engineer       1.00      1.00      1.00        14\n",
      "Network Security Engineer       1.00      1.00      1.00        16\n",
      "       Operations Manager       1.00      1.00      1.00        20\n",
      "                      PMO       1.00      1.00      1.00        16\n",
      "         Python Developer       1.00      1.00      1.00        20\n",
      "            SAP Developer       1.00      1.00      1.00        15\n",
      "                    Sales       1.00      1.00      1.00        17\n",
      "                  Testing       1.00      1.00      1.00        12\n",
      "            Web Designing       1.00      1.00      1.00        10\n",
      "\n",
      "                 accuracy                           1.00       420\n",
      "                macro avg       1.00      1.00      1.00       420\n",
      "             weighted avg       1.00      1.00      1.00       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5463fe2e",
   "metadata": {},
   "source": [
    "# Performing The Prediction On a Random Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7429b9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test='''Professional Summary\n",
    "Innovative and results-driven Data Scientist with expertise in applying advanced statistical techniques and machine learning algorithms, including\n",
    "regression, classification, clustering, time series analysis, and natural language processing (NLP). Proficient in Python and R, with hands-on\n",
    "experience in designing neural networks and deep learning models. Adept at leveraging data-driven insights to drive strategic decisions, with\n",
    "strong communication, consulting, and project management skills. Holds a B.Tech in Mechatronics and a Post Graduation Diploma In Data\n",
    "Science.\n",
    "Experience\n",
    "Wahy Lab Solutions Kochi\n",
    "Data Scientist 12/2022 - 12/2023\n",
    "• Analyzed large datasets to identify patterns and actionable insights that informed business strategy, improving decision-making .\n",
    "• Developed and validated predictive models to forecast key business metrics, achieving 80% accuracy and providing valuable foresight\n",
    "for strategic planning.\n",
    "• Designed and conducted A/B tests to evaluate and optimize marketing and operational strategies, increasing conversion rates.\n",
    "• Created and maintained interactive dashboards in Power BI to visualize key metrics, enabling stakeholders to monitor business\n",
    "performance and insights in real-time.\n",
    "• Documented data processes, model architecture, and code for transparency and to ensure reproducibility across teams.\n",
    "Skill Vertex Bangalore\n",
    "Data science Intern 06/2021 - 08/2021\n",
    "• Utilized Python, SQL, and R to process and clean data from multiple sources, ensuring data quality and readiness for analysis.\n",
    "• Built statistical and machine learning models to understand customer behavior, achieving improvement in targeted campaign\n",
    "effectiveness.\n",
    "• Collaborated with cross-functional teams to translate analytical insights into business strategies that improved customer engagement.\n",
    "• Created visualizations using Tableau and matplotlib, simplifying complex findings for non-technical audiences.\n",
    "Education\n",
    "Prist University Chennai\n",
    "Bachelor of Technology in Mechatronics 08/2018 - 06/2022\n",
    "Ims Proschool Mumbai\n",
    "Post Graduation Diploma in Data Science 09/2021 - 09/2022\n",
    "Technical skills\n",
    "• Data Visualization • Statistical Analytics\n",
    "• Python • Scikit-learn\n",
    "• R programming • Tableau\n",
    "• TensorFlow • Microsoft azure\n",
    "• Power BI • SQL\n",
    "• OpenCV • Data Extraction\n",
    "• Data Manipulation • Predictive Modeling\n",
    "• Communication • Collaborative\n",
    "• Critical Thinking\n",
    "CERTIFICATIONS\n",
    "PGDM IN DATASCIENCE\n",
    "01/2023\n",
    "DATA SCIENCE TRAINING\n",
    "05/2021\n",
    "PROJECTS\n",
    "Sales Forecasting with Time Series Analysis\n",
    "• Built and deployed a time series model to forecast monthly sales for a retail business, enabling data-driven inventory and pricing\n",
    "decisions.\n",
    "• Implemented feature engineering to extract trends, seasonality, and additional temporal features, improving model performance.\n",
    "• Leveraged Python libraries like Prophet and ARIMA, achieving a 20% improvement in forecast accuracy over the previous model.\n",
    "Document Digitization and Analysis with OCR and NLP\n",
    "• Objective: Built a pipeline to digitize and analyze data from scanned documents (PDFs and images) using Optical Character Recognition\n",
    "(OCR) and Natural Language Processing (NLP).\n",
    "• Skills Used: Used Tesseract OCR to extract text from images and PDFs, then applied NLP techniques to categorize and summarize\n",
    "information.\n",
    "• Outcome: Created an organized and searchable database, making document retrieval faster and supporting business decision-making\n",
    "processes.\n",
    "Sales Enablement Dashboard\n",
    "• Created a Power BI dashboard to visualize and track sales performance against targets, enhancing client reporting and driving data-based\n",
    "decision-making.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c83bd8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=cleaned_text(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9801ff4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'professional summary innovative and resultsdriven data scientist with expertise in applying advanced statistical techniques and machine learning algorithms including regression classification clustering time series analysis and natural language processing nlp proficient in python and r with handson experience in designing neural networks and deep learning models adept at leveraging datadriven insights to drive strategic decisions with strong communication consulting and project management skills holds a btech in mechatronics and a post graduation diploma in data science experience wahy lab solutions kochi data scientist analyzed large datasets to identify patterns and actionable insights that informed business strategy improving decisionmaking developed and validated predictive models to forecast key business metrics achieving accuracy and providing valuable foresight for strategic planning designed and conducted ab tests to evaluate and optimize marketing and operational strategies increasing conversion rates created and maintained interactive dashboards in power bi to visualize key metrics enabling stakeholders to monitor business performance and insights in realtime documented data processes model architecture and code for transparency and to ensure reproducibility across teams skill vertex bangalore data science intern utilized python sql and r to process and clean data from multiple sources ensuring data quality and readiness for analysis built statistical and machine learning models to understand customer behavior achieving improvement in targeted campaign effectiveness collaborated with crossfunctional teams to translate analytical insights into business strategies that improved customer engagement created visualizations using tableau and matplotlib simplifying complex findings for nontechnical audiences education prist university chennai bachelor of technology in mechatronics ims proschool mumbai post graduation diploma in data science technical skills data visualization statistical analytics python scikitlearn r programming tableau tensorflow microsoft azure power bi sql opencv data extraction data manipulation predictive modeling communication collaborative critical thinking certifications pgdm in datascience data science training projects sales forecasting with time series analysis built and deployed a time series model to forecast monthly sales for a retail business enabling datadriven inventory and pricing decisions implemented feature engineering to extract trends seasonality and additional temporal features improving model performance leveraged python libraries like prophet and arima achieving a improvement in forecast accuracy over the previous model document digitization and analysis with ocr and nlp objective built a pipeline to digitize and analyze data from scanned documents pdfs and images using optical character recognition ocr and natural language processing nlp skills used used tesseract ocr to extract text from images and pdfs then applied nlp techniques to categorize and summarize information outcome created an organized and searchable database making document retrieval faster and supporting business decisionmaking processes sales enablement dashboard created a power bi dashboard to visualize and track sales performance against targets enhancing client reporting and driving databased decisionmaking'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "817ab22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=['professional summary innovative and resultsdriven data scientist with expertise in applying advanced statistical techniques and machine learning algorithms including regression classification clustering time series analysis and natural language processing nlp proficient in python and r with handson experience in designing neural networks and deep learning models adept at leveraging datadriven insights to drive strategic decisions with strong communication consulting and project management skills holds a btech in mechatronics and a post graduation diploma in data science experience wahy lab solutions kochi data scientist analyzed large datasets to identify patterns and actionable insights that informed business strategy improving decisionmaking developed and validated predictive models to forecast key business metrics achieving accuracy and providing valuable foresight for strategic planning designed and conducted ab tests to evaluate and optimize marketing and operational strategies increasing conversion rates created and maintained interactive dashboards in power bi to visualize key metrics enabling stakeholders to monitor business performance and insights in realtime documented data processes model architecture and code for transparency and to ensure reproducibility across teams skill vertex bangalore data science intern utilized python sql and r to process and clean data from multiple sources ensuring data quality and readiness for analysis built statistical and machine learning models to understand customer behavior achieving improvement in targeted campaign effectiveness collaborated with crossfunctional teams to translate analytical insights into business strategies that improved customer engagement created visualizations using tableau and matplotlib simplifying complex findings for nontechnical audiences education prist university chennai bachelor of technology in mechatronics ims proschool mumbai post graduation diploma in data science technical skills data visualization statistical analytics python scikitlearn r programming tableau tensorflow microsoft azure power bi sql opencv data extraction data manipulation predictive modeling communication collaborative critical thinking certifications pgdm in datascience data science training projects sales forecasting with time series analysis built and deployed a time series model to forecast monthly sales for a retail business enabling datadriven inventory and pricing decisions implemented feature engineering to extract trends seasonality and additional temporal features improving model performance leveraged python libraries like prophet and arima achieving a improvement in forecast accuracy over the previous model document digitization and analysis with ocr and nlp objective built a pipeline to digitize and analyze data from scanned documents pdfs and images using optical character recognition ocr and natural language processing nlp skills used used tesseract ocr to extract text from images and pdfs then applied nlp techniques to categorize and summarize information outcome created an organized and searchable database making document retrieval faster and supporting business decisionmaking processes sales enablement dashboard created a power bi dashboard to visualize and track sales performance against targets enhancing client reporting and driving databased decisionmaking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10190e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=vect.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d72821c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data Science'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02df0f9",
   "metadata": {},
   "source": [
    "# Preforming a Grid Search to improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e058860",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfaeb4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],    # Number of trees\n",
    "    'max_depth': [None, 10, 20],      # Maximum depth of trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples to split\n",
    "    'min_samples_leaf': [1, 2, 4]     # Minimum samples per leaf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be6d72b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,              # 5-fold cross-validation\n",
    "    scoring='accuracy', # Metric for evaluation\n",
    "    verbose=2,          # Verbosity level\n",
    "    n_jobs=-1           # Use all available processors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0142b4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 10, 20],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [10, 50, 100]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0161b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Best Cross-Validation Accuracy: 0.9994047619047619\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "583edff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b91e28",
   "metadata": {},
   "source": [
    "# Downloading the model as a picke file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8ee81c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resume screening model.pkl']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(best_model,\"resume screening model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9715c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vect,\"tfidf_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "403c2cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Science']\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Load the model and vectorizer\n",
    "model = load('resume screening model.pkl')\n",
    "vectorizer = load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Test with example text\n",
    "example_text = [\"Experienced data scientist with strong Python skills\"]\n",
    "features = vectorizer.transform(example_text)\n",
    "print(model.predict(features)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddc35a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
